% Appendix grade proof chain for SecureClaw and artifact faithful.
%
% This file is intended to be \input{} from neurips_2025.tex. It is also
% readable standalone as a LaTeX appendix fragment.

\section{Appendix: Proof Chain for Non bypassable Effects and Composition}
\label{app:proofs}

This appendix formalizes SecureClaw's core integrity claim, \emph{no external side effect is
committed without two independently authenticated commit proofs bound to the exact request}, and it
sketches a compositional argument with the privacy and confinement components.
The statements match the artifact implementation in \texttt{executor\_server/server.py} and
\texttt{policy\_server/server.py}, and the formal harness \texttt{scripts/security\_game\_nbe\_check.py}.

\paragraph{Scope and assumptions.}
We reason about a PPT adversary that fully controls the untrusted agent runtime and all skill code,
and may send arbitrary requests to the gateway and the executor. The executor's MAC verification keys
are not compromised.
Policy servers are assumed honest for integrity and they compute commit proofs according to the
protocol.
Policy servers are also assumed honest but curious for privacy.
Single server leakage is bounded by an explicit leakage function defined in \texttt{LEAKAGE\_MODEL.md}.

\subsection{Cryptographic primitives and canonical binding}
\label{app:proofs:primitives}

\paragraph{MAC.}
Let $\mathsf{MAC} = (\mathsf{Tag},\mathsf{Vrfy})$ be a message authentication code with key space
$\mathcal{K}$ and message space $\mathcal{M}$. We assume existential unforgeability under chosen
message attack, abbreviated EUF CMA. The artifact uses HMAC-SHA256:
\[
\mathsf{Tag}_K(m) := \mathrm{HMAC\text{-}SHA256}(K, m), \quad \mathsf{Vrfy}_K(m,t) := [t = \mathsf{Tag}_K(m)].
\]

\paragraph{Canonical serialization and request binding hash.}
Let $\mathsf{Canon}(\cdot)$ be a deterministic canonical JSON serialization implemented in
\texttt{common/canonical.py}. Define the request binding hash:
\[
\mathsf{ReqHash}(\mathsf{intent\_id},\mathsf{caller},\mathsf{session},\mathsf{inputs}) :=
\mathrm{SHA256}\!\left(\mathsf{Canon}\!\left(
\begin{array}{l}
\{\texttt{"intent\_id"}:\mathsf{intent\_id},\ \texttt{"caller"}:\mathsf{caller},\ \texttt{"session"}:\mathsf{session},\\
\ \texttt{"inputs"}:\mathsf{inputs}\}
\end{array}\right)\right).
\]
We assume SHA-256 collision resistance and \emph{binding hash consistency}: both gateway and executor
compute identical byte strings under $\mathsf{Canon}(\cdot)$ for semantically equal JSON objects.
This is an engineering assumption enforced by using the same library routine in both places.

\subsection{Commit proof syntax and executor acceptance predicate}
\label{app:proofs:accept}

Each policy server $\mathcal{P}_\sigma$ for $\sigma\in\{0,1\}$ holds a MAC key $K_\sigma$ and uses a
key identifier field \texttt{kid} for rotation.
Each policy server issues \emph{commit proof shares}. A commit proof share is a pair
$\pi_\sigma = (\mathsf{meta}_\sigma, t_\sigma)$, where:
\begin{align*}
\mathsf{meta}_\sigma := \{&
\texttt{"v"}:1,\ \texttt{"kind"}:\texttt{"commit"},\ \texttt{"server\_id"}:\sigma,\ \texttt{"kid"}:\mathrm{kid},\ \texttt{"ts"}:\tau,\\
&\texttt{"action\_id"}:a,\ \texttt{"program\_id"}:p,\ \texttt{"request\_sha256"}:h,\\
&\texttt{"outputs"}:y_\sigma,\ \texttt{"commit\_tag\_share"}:\mathrm{tag}_\sigma\},
\end{align*}
and $t_\sigma := \mathsf{Tag}_{K_\sigma}(\mathsf{Canon}(\mathsf{meta}_\sigma))$.
The artifact computes and verifies these fields in:
\texttt{policy\_server/server.py:/mpc/finalize} and
\texttt{executor\_server/server.py:\_verify\_commit\_evidence}.

\paragraph{Executor acceptance.}
Given an effect request $\mathsf{req}$ and two purported commit proof shares $\pi_0,\pi_1$, the
executor $\mathcal{X}$ accepts if and only if the predicate $\mathsf{Accept}(\mathsf{req},\pi_0,\pi_1)$
holds, where:
\begin{enumerate}
\item Both shares parse, have \texttt{v=1} and \texttt{kind="commit"}, and claim distinct
\texttt{server\_id} values in $\{0,1\}$.
\item MAC verification succeeds:
$\mathsf{Vrfy}_{K_\sigma}(\mathsf{Canon}(\mathsf{meta}_\sigma), t_\sigma)=1$ for $\sigma\in\{0,1\}$,
using the key for the claimed \texttt{kid}.
\item Freshness: $\lvert \mathrm{now} - \tau\rvert \leq \mathrm{TTL}_{\mathsf{mac}}$
where $\mathrm{TTL}_{\mathsf{mac}}$ is configured by the environment variable \texttt{POLICY\_MAC\_TTL\_S}.
\item Context agreement: both shares bind the same $(a,p,h)$ tuple.
\item Request binding: letting $(\mathsf{intent\_id},\mathsf{caller},\mathsf{session},\mathsf{inputs})$
be the effectful fields of $\mathsf{req}$, we require $h =
\mathsf{ReqHash}(\mathsf{intent\_id},\mathsf{caller},\mathsf{session},\mathsf{inputs})$.
\item Replay protection: the action identifier $a$ has not been accepted before within the replay
window. The artifact uses \texttt{\_ReplayGuard.check\_and\_mark}.
\item Policy bits reconstructed from $(y_0,y_1)$ indicate allow; if a confirmation bit is set then
the request includes explicit user confirmation; and any sanitize patch is applied.
\end{enumerate}

\subsection{Security game for non bypassable effects}
\label{app:proofs:nbe-game}

We formalize \emph{non bypassable effects} as an integrity game where the adversary controls the
untrusted runtime and can obtain valid commit proofs for adaptively chosen preview tuples, but must
not be able to commit an effect outside the authorized set.

\paragraph{Oracles.}
The challenger provides a \emph{commit oracle} $\mathcal{O}_{\mathsf{commit}}(\rho)$ that, on input
$\rho = (\mathsf{intent\_id},\mathsf{caller},\mathsf{session},\mathsf{inputs})$, returns a fresh
action id $a$ and valid proof shares $(\pi_0,\pi_1)$ whose \texttt{request\_sha256} equals
$\mathsf{ReqHash}(\rho)$. The challenger records the authorized binding tuple
$(a,p,\mathsf{ReqHash}(\rho),\rho)$ in a set $\mathcal{S}$.

\paragraph{Experiment $\mathsf{Exp}^{\mathsf{NBE}}(\lambda)$.}
\begin{enumerate}
\item The challenger samples independent MAC keys $K_0,K_1 \leftarrow \mathcal{K}$ and initializes
replay state empty.
\item The adversary $\mathcal{A}$ may adaptively query $\mathcal{O}_{\mathsf{commit}}(\rho)$.
\item $\mathcal{A}$ outputs an effect request $\mathsf{req}^\star$ and two shares
$(\pi_0^\star,\pi_1^\star)$.
\item $\mathcal{A}$ wins if $\mathsf{Accept}(\mathsf{req}^\star,\pi_0^\star,\pi_1^\star)=1$ and at
least one of the following holds:
\begin{enumerate}
\item \textbf{No-auth:} the accepted $(a^\star,p^\star,h^\star)$ tuple is not in $\mathcal{S}$.
\item \textbf{Binding break:} $(a^\star,p^\star,h^\star)$ is in $\mathcal{S}$, but the request
tuple $\rho(\mathsf{req}^\star)$ differs from the $\rho$ recorded for that context.
\item \textbf{Replay:} the executor accepts the same $a^\star$ twice within the replay window.
\end{enumerate}
\end{enumerate}

\subsection{Main theorem: no side effects without dual proofs}
\label{app:proofs:nbe-thm}

\begin{theorem}[No side effects without dual commit proofs]\label{thm:nbe}
Assume (i) $\mathsf{MAC}$ is EUF-CMA secure; (ii) SHA-256 is collision resistant and
$\mathsf{Canon}(\cdot)$ is consistent; (iii) the executor enforces $\mathsf{Accept}$ as specified and
its replay state does not lose entries within the replay window. Then for any PPT adversary
$\mathcal{A}$ there exist PPT reductions $\mathcal{B}_0,\mathcal{B}_1,\mathcal{C}$ such that:
\[
\Pr[\mathsf{Exp}^{\mathsf{NBE}}(\lambda)=1]
\le \mathrm{Adv}^{\mathrm{euf\text{-}cma}}_{\mathsf{MAC}}(\mathcal{B}_0)
 + \mathrm{Adv}^{\mathrm{euf\text{-}cma}}_{\mathsf{MAC}}(\mathcal{B}_1)
 + \mathrm{Adv}^{\mathrm{coll}}_{\mathrm{SHA256}}(\mathcal{C})
 + \varepsilon_{\mathrm{replay}}(\lambda),
\]
where $\varepsilon_{\mathrm{replay}}$ captures only non-cryptographic replay-store failures excluded
from the model.
\end{theorem}

\paragraph{Proof (reduction by cases).}
Fix an adversary $\mathcal{A}$ that wins the experiment and consider the accepting transcript
$(\mathsf{req}^\star,\pi_0^\star,\pi_1^\star)$.
By acceptance, both MACs verify and both meta records bind the same context
$(a^\star,p^\star,h^\star)$ with fresh timestamps, and $h^\star$ equals the executor's recomputed
$\mathsf{ReqHash}(\rho(\mathsf{req}^\star))$.

\emph{Case 1 (No-auth).} Suppose $(a^\star,p^\star,h^\star)\not\in\mathcal{S}$. The challenger never
queried its own commit oracle on the message $\mathsf{Canon}(\mathsf{meta}_0^\star)$ or
$\mathsf{Canon}(\mathsf{meta}_1^\star)$ for this context. Since both tags verify, at least one share
is a fresh valid tag on a message not previously tagged under the corresponding key. We build a UF-CMA
forger $\mathcal{B}_0$ (symmetrically $\mathcal{B}_1$) that embeds its UF-CMA challenge key as $K_0$,
answers $\mathcal{O}_{\mathsf{commit}}$ by querying its signing oracle for $\mathsf{Canon}(\mathsf{meta}_0)$,
and outputs $(\mathsf{Canon}(\mathsf{meta}_0^\star),t_0^\star)$ when $\mathcal{A}$ wins in this case.

\emph{Case 2 (Binding break).} Suppose $(a^\star,p^\star,h^\star)\in\mathcal{S}$, but
$\rho(\mathsf{req}^\star)\neq \rho$ recorded for that context. Acceptance implies:
\[
h^\star = \mathsf{ReqHash}(\rho(\mathsf{req}^\star)) = \mathsf{ReqHash}(\rho).
\]
If $\rho(\mathsf{req}^\star)\neq \rho$ then we have found a collision in SHA-256 \emph{under the
canonical encoding} (or an inconsistency in $\mathsf{Canon}$). A reduction $\mathcal{C}$ outputs the
two distinct canonical inputs whose hashes are equal. This contradicts collision resistance or the
engineering consistency assumption.

\emph{Case 3 (Replay).} If the executor accepts a previously accepted $a^\star$ within the replay
window, then the replay guard's check-and-mark failed due to loss/corruption of replay state or lack
of atomicity. This is outside the cryptographic model and is captured by $\varepsilon_{\mathrm{replay}}$.

Taking a union bound over the cases yields the theorem.
\qed

\subsection{Session, caller, TTL binding}
\label{app:proofs:binding}

Theorem~\ref{thm:nbe} already incorporates binding of $\mathsf{caller}$ and $\mathsf{session}$ because
they are included in $\mathsf{ReqHash}$. Freshness (TTL) is enforced by the executor's timestamp
check. Thus, any attempt to reuse a commit proof for a different caller, session, or effectful input
must either fail MAC verification/binding checks or imply a hash collision.

\subsection{Composition with privacy and confinement}
\label{app:proofs:composition}

We state a composition theorem that makes the conjunction of properties explicit.

\paragraph{Combined experiment.}
Define a combined experiment $\mathsf{Exp}^{\mathsf{SC}}(\lambda)$ for SecureClaw.
The adversary controls the untrusted runtime and all skills and may send arbitrary requests to the
gateway and the executor.
The adversary may also corrupt at most one policy server and obtain its full internal view.
The experiment outputs $1$ if any of the following bad events occurs.

\begin{itemize}
\item $\mathsf{Bad}_{\mathsf{NBE}}$: an external side effect is committed without two valid commit proofs
bound to the exact request hash, within the freshness window, and not replayed.
\item $\mathsf{Bad}_{\mathsf{SM}}$: the adversary learns a sensitive plaintext value that is not in the
explicit declassification leakage $L_{\mathsf{SM}}$.
\item $\mathsf{Bad}_{\mathsf{SAP}}$: the adversary distinguishes two action sequences with equal leakage
under $L_{\mathsf{policy}}$ by observing the full transcript view of one policy server.
\item $\mathsf{Bad}_{\mathsf{SCS}}$: while the capsule mediation contract holds, the adversary performs a
forbidden direct action that bypasses the gateway and executor.
\end{itemize}

\begin{theorem}[Composition of SecureClaw properties]\label{thm:composition}
Assume the conditions of Theorems \ref{thm:nbe}, \ref{thm:sm}, \ref{thm:sap}, and \ref{thm:scs}.
Then for any probabilistic polynomial time adversary $\mathcal{A}$ the winning probability in the
combined experiment satisfies
\[
\Pr[\mathsf{Exp}^{\mathsf{SC}}(\lambda)=1]
\le
\Pr[\mathsf{Bad}_{\mathsf{NBE}}]
\;+\;
\Pr[\mathsf{Bad}_{\mathsf{SM}}]
\;+\;
\Pr[\mathsf{Bad}_{\mathsf{SAP}}]
\;+\;
\Pr[\mathsf{Bad}_{\mathsf{SCS}}].
\]
Moreover, each term is negligible in $\lambda$ under the corresponding theorem assumptions.
\end{theorem}

\paragraph{Proof.}
The combined experiment outputs $1$ if and only if at least one bad event occurs.
By the union bound,
\[
\Pr[\mathsf{Bad}_{\mathsf{NBE}} \lor \mathsf{Bad}_{\mathsf{SM}} \lor \mathsf{Bad}_{\mathsf{SAP}} \lor \mathsf{Bad}_{\mathsf{SCS}}]
\le
\Pr[\mathsf{Bad}_{\mathsf{NBE}}] + \Pr[\mathsf{Bad}_{\mathsf{SM}}] + \Pr[\mathsf{Bad}_{\mathsf{SAP}}] + \Pr[\mathsf{Bad}_{\mathsf{SCS}}].
\]
Theorem \ref{thm:nbe} bounds $\Pr[\mathsf{Bad}_{\mathsf{NBE}}]$ by MAC unforgeability, hash collision
resistance, and replay store reliability.
Theorem \ref{thm:sm} bounds $\Pr[\mathsf{Bad}_{\mathsf{SM}}]$ by the handleization and declassification
assumptions.
Theorem \ref{thm:sap} bounds $\Pr[\mathsf{Bad}_{\mathsf{SAP}}]$ by PIR and two party computation
security up to the stated leakage.
Theorem \ref{thm:scs} bounds $\Pr[\mathsf{Bad}_{\mathsf{SCS}}]$ by the capsule mediation contract and
the integrity and confidentiality properties of the gateway and executor path.
\qed

\subsection{Capsule mediation contract as a system assumption}
\label{app:proofs:mc}

We define the capsule mediation contract as an explicit system assumption that can be validated by
platform specific configurations and tests.

\paragraph{Contract definition.}
Let $MC$ be a predicate over the runtime environment and its execution.
The contract requires the following properties.

\begin{itemize}
\item Filesystem confinement. The runtime can read only its code and a dedicated workspace directory.
The runtime cannot read host secret paths such as SSH keys or application credential stores.
\item Network confinement. The runtime cannot initiate public network connections.
If a network stack is used for transport then only the gateway address is reachable.
\item Process confinement. The runtime cannot spawn arbitrary processes.
Only a fixed allowlist required for the runtime operation is permitted.
\item Transport confinement. The runtime can reach the gateway only through a single constrained
transport endpoint, preferably a Unix domain socket.
\end{itemize}

\paragraph{Cross platform minimal realizations.}
The artifact provides a macOS capsule policy using \texttt{sandbox-exec} with profile
\texttt{capsule/capsule.sb}, and a Linux capsule policy using \texttt{bubblewrap} with a network
namespace in \texttt{capsule/run\_smoke\_linux.sh}.
Both realizations use a constrained gateway transport and are exercised by the same smoke test logic
in \texttt{capsule/smoke.py}.

\paragraph{Testable assertions.}
The smoke test asserts that direct reads of a host secret path fail, that direct public network
requests fail, that direct HTTP posts to a local exfiltration endpoint fail when the capsule is
configured for a netless transport, that direct process execution is denied in the macOS capsule
configuration, and that a gateway action request succeeds through the constrained transport.
These assertions are recorded as a structured JSON report.

\subsection{Executable validation of the acceptance predicate}
\label{app:proofs:executable}

Theorem \ref{thm:nbe} is a cryptographic statement about any adversary in the model.
The artifact also provides an executable specification that checks the concrete acceptance predicate
implemented by the executor.

\paragraph{Validation statement.}
Let $\mathsf{Accept}$ be the acceptance predicate specified in Section \ref{app:proofs:accept}.
The artifact implements $\mathsf{Accept}$ in \texttt{executor\_server/server.py} and provides:
\begin{itemize}
\item unit tests that directly call the verification routine and assert accept and reject behavior,
in \texttt{tests/test\_security\_games.py};
\item an end to end harness that starts two policy servers, a gateway, and an executor and checks a
suite of mutated requests, in \texttt{scripts/security\_game\_nbe\_check.py}.
\end{itemize}
The harness checks rejection under replay, session mismatch, caller mismatch, missing proof share,
MAC mutation, request hash mutation, action identifier mutation, and timestamp expiration.
These checks provide code level evidence that the artifact enforces the exact acceptance predicate
assumed by the reduction in Theorem \ref{thm:nbe}.

\subsection{Secret myopia game and theorem}
\label{app:proofs:sm}

We formalize secret myopia as a simulation based confidentiality property for the untrusted runtime.
The definition is implementation oriented.
It treats the gateway and executor as trusted and asserts that sensitive plaintext does not flow to
the untrusted runtime except through an explicit declassification interface.

\paragraph{Leakage function for SM.}
Let $L_{\mathsf{SM}}$ include:
handle identifiers,
handle labels,
handle time to live values,
policy decision bits,
sanitization patch identifiers,
and any explicitly declassified outputs that follow user confirmation.
It excludes any other function of sensitive plaintext stored inside the gateway.

\paragraph{Experiment $\mathsf{Exp}^{\mathsf{SM}}(\lambda)$.}
The challenger initializes the gateway and gives the adversary control of the untrusted runtime.
The adversary interacts with the gateway by issuing arbitrary action requests and receiving gateway
responses.
The adversary wins if it outputs a bit indicating which of two challenger chosen secret values was
stored in a handle, with advantage non negligible over one half, without an allowed declassification
event that reveals that value.

\paragraph{Theorem.}
\begin{theorem}[Secret myopia by handleization]\label{thm:sm}
Assume the gateway never returns sensitive plaintext to the untrusted runtime except through an
explicit declassification interface that requires confirmation and includes declassified content in
$L_{\mathsf{SM}}$.
Assume handle identifiers are sampled independently of plaintext and are not guessable with non
negligible probability.
Then the system satisfies secret myopia with leakage $L_{\mathsf{SM}}$.
\end{theorem}

\paragraph{Proof.}
We construct a simulator $\mathcal{S}$ that, given $L_{\mathsf{SM}}$, produces a distribution
indistinguishable from the view of the adversary.
Whenever the real gateway would mint a handle bound to some plaintext, $\mathcal{S}$ instead mints a
fresh random handle identifier and records only the public metadata required by $L_{\mathsf{SM}}$.
All subsequent uses of that handle by the adversary are simulated by lookup on the simulator side.
Because handle identifiers are sampled independently of plaintext and the adversary never receives
plaintext unless it appears in the leakage, the simulated responses match the real responses
distribution exactly up to the declassified outputs that are already included in $L_{\mathsf{SM}}$.
Therefore any adversary advantage implies a violation of the handle sampling assumption or a direct
plaintext flow outside the declassification interface, which contradicts the premise.
\qed

\paragraph{Executable evidence.}
The artifact includes unit tests that check handleization and declassification behavior for the tool
surface and for inter agent and memory channels.
Representative tests are in \texttt{tests/test\_mcp\_gateway.py} and \texttt{tests/test\_agentleak\_channels.py}.

\subsection{Single auditor privacy game and theorem}
\label{app:proofs:sap}

We formalize single auditor privacy as transcript indistinguishability for a single policy server,
parameterized by an explicit leakage function.
The leakage function is defined in Appendix \ref{app:leakage}.

\paragraph{Experiment $\mathsf{Exp}^{\mathsf{SAP}}(\lambda)$.}
The adversary outputs two action sequences $W_0$ and $W_1$ such that
$L_{\mathsf{policy}}(W_0) = L_{\mathsf{policy}}(W_1)$.
The challenger samples a bit $b$ and executes the system on $W_b$.
The challenger then reveals the full transcript view $\mathsf{View}(\mathcal{P}_\sigma)$ for one
policy server $\mathcal{P}_\sigma$.
The adversary outputs a guess $b'$.

\paragraph{Theorem.}
\begin{theorem}[Single auditor privacy under DPF and two party computation]\label{thm:sap}
Assume the DPF and FSS based two server PIR scheme is secure against a single server that sees only
one key share per query.
Assume the two party computation protocol for the fixed policy program is secure in the honest but
curious model.
Assume the gateway uses fixed shape routing and fixed schedule parameters so that the transcript
shape matches the leakage function $L_{\mathsf{policy}}$.
Then for each $\sigma \in \{0,1\}$ there exists a probabilistic polynomial time simulator
$\mathsf{Sim}_\sigma$ such that for all probabilistic polynomial time distinguishers $D$,
\[
\bigl|\Pr[D(\mathsf{View}(\mathcal{P}_\sigma))=1] - \Pr[D(\mathsf{Sim}_\sigma(L_{\mathsf{policy}}))=1]\bigr|
\]
is negligible in $\lambda$.
\end{theorem}

\paragraph{Proof.}
We use a hybrid argument.
Fix $\sigma$ and consider the real transcript view of $\mathcal{P}_\sigma$.

First replace each PIR key share in the transcript with the output of the single server PIR
simulator for that scheme given the corresponding PIR leakage terms in $L_{\mathsf{policy}}$.
By PIR security the transcript remains computationally indistinguishable.

Next replace each two party computation message transcript with the output of the two party
computation simulator for the honest but curious model given the circuit shape, the program
identifier, the schedule parameters, and the output bits that are included in $L_{\mathsf{policy}}$.
By two party computation security the transcript remains computationally indistinguishable.

All remaining transcript components are fully determined by the fixed routing and fixed schedule
parameters and are therefore computable from $L_{\mathsf{policy}}$.
Combining the simulators yields $\mathsf{Sim}_\sigma$.
Applying a union bound over the negligible distinguishing advantages yields the theorem.
\qed

\paragraph{Executable evidence.}
The artifact includes fixed shape mixing and padding logic for PIR and for the unified policy program.
The mixer constant shape property is exercised by unit tests such as
\texttt{tests/test\_algorithms.py}.
End to end distinguishability sweeps are implemented in \texttt{scripts/leakage\_model\_sweep.py}.

\subsection{Skill confined safety game and theorem}
\label{app:proofs:scs}

Skill confined safety is a conditional property.
It relies on a capsule mediation contract that constrains the untrusted runtime environment.
The contract is specified in Section \ref{sec:limits}.

\paragraph{Experiment $\mathsf{Exp}^{\mathsf{SCS}}(\lambda)$.}
The adversary controls the skill code and attempts to perform one of the following forbidden direct
actions without using the gateway and executor path:
host secret reads, public network exfiltration, or arbitrary process execution.
The adversary wins if it succeeds while the capsule mediation contract holds.

\paragraph{Theorem.}
\begin{theorem}[Skill confined safety under a capsule mediation contract]\label{thm:scs}
Assume the capsule mediation contract holds and prevents the forbidden direct actions.
Assume non bypassable effects and secret myopia hold for the gateway and executor path.
Then the system satisfies skill confined safety.
\end{theorem}

\paragraph{Proof.}
By the capsule mediation contract, any forbidden direct action attempt that does not traverse the
gateway fails and cannot reach an external sink.
Therefore any external side effect must traverse the executor, which enforces non bypassable effects.
Any attempted exfiltration of sensitive plaintext through allowed interfaces is prevented by secret
myopia unless the user explicitly declassifies it, in which case the leakage is intentional and
auditable.
Thus the adversary cannot perform forbidden direct actions or unauthorized effects under the stated
assumptions.
\qed

\paragraph{Executable evidence.}
The artifact provides a capsule smoke test that attempts direct filesystem reads, direct network
access, and direct process execution from within the capsule boundary and asserts denial.
